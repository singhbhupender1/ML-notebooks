{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Weight Regularization to reduce overfitting of DL model.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyP+660NGBppntUffjQWXZV1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/singhbhupender1/ML-notebooks/blob/master/Weight_Regularization_to_reduce_overfitting_of_DL_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Azce5iR2k06i",
        "colab_type": "text"
      },
      "source": [
        "##Problem With Large Weights\n",
        "**When fitting a neural network model, we must learn the weights of the network (i.e. the model parameters) using stochastic gradient descent and the training dataset.**\n",
        "\n",
        "**The longer we train the network, the more specialized the weights will become to the training data, overfitting the training data. The weights will grow in size in order to handle the specifics of the examples seen in the training data.**\n",
        "\n",
        "**Large weights make the network unstable. Although the weight will be specialized to the training dataset, minor variation or statistical noise on the expected inputs will result in large differences in the output.**\n",
        "\n",
        "**Generally, we refer to this model as having a large variance and a small bias. That is, the model is sensitive to the specific examples, the statistical noise, in the training dataset.**\n",
        "\n",
        "**A model with large weights is more complex than a model with smaller weights. It is a sign of a network that may be overly specialized to training data. **\n",
        "\n",
        "**Another possible issue is that there may be many input variables, each with different levels of relevance to the output variable. Sometimes we can use methods to aid in selecting input variables, but often the interrelationships between variables is not obvious.**\n",
        "\n",
        "**Having small weights or even zero weights for less relevant or irrelevant inputs to the network will allow the model to focus learning. This too will result in a simpler model.**\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jIDvbOCYuXBP",
        "colab_type": "text"
      },
      "source": [
        "##Encourage Small Weights\n",
        "**The learning algorithm can be updated to encourage the network toward using small weights.**\n",
        "\n",
        "**One way to do this is to change the calculation of loss used in the optimization of the network to also consider the size of the weights.**\n",
        "\n",
        "**Remember, that when we train a neural network, we minimize a loss function, such as the log loss in classification or mean squared error in regression. In calculating the loss between the predicted and expected values in a batch, we can add the current size of all weights in the network or add in a layer to this calculation. This is called a penalty because we are penalizing the model proportional to the size of the weights in the model.**\n",
        "\n",
        "**Larger weights result in a larger penalty, in the form of a larger loss score. The optimization algorithm will then push the model to have smaller weights, i.e. weights no larger than needed to perform well on the training dataset.**\n",
        "\n",
        "**Smaller weights are considered more regular or less specialized and as such, we refer to this penalty as weight regularization.**\n",
        "\n",
        "**When this approach of penalizing model coefficients is used in other machine learning models such as linear regression or logistic regression, it may be referred to as shrinkage, because the penalty encourages the coefficients to shrink during the optimization process.**\n",
        "\n",
        "**The addition of a weight size penalty or weight regularization to a neural network has the effect of reducing generalization error and of allowing the model to pay less attention to less relevant input variables.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TrKuNdu3uzUx",
        "colab_type": "text"
      },
      "source": [
        "##How to Penalize Large Weights\n",
        "**There are two parts to penalizing the model based on the size of the weights.**\n",
        "\n",
        "**The first is the calculation of the size of the weights, and the second is the amount of attention that the optimization process should pay to the penalty.**\n",
        "\n",
        "###Calculate Weight Size\n",
        "**Neural network weights are real-values that can be positive or negative, as such, simply adding the weights is not sufficient. There are two main approaches used to calculate the size of the weights, they are:**\n",
        "\n",
        "**.Calculate the sum of the absolute values of the weights, called L1.**\n",
        "\n",
        "**.Calculate the sum of the squared values of the weights, called L2.**\n",
        "\n",
        "**L1 encourages weights to 0.0 if possible, resulting in more sparse weights (weights with more 0.0 values). L2 offers more nuance, both penalizing larger weights more severely, but resulting in less sparse weights. The use of L2 in linear and logistic regression is often referred to as Ridge Regression. This is useful to know when trying to develop an intuition for the penalty or examples of its usage.**\n",
        "\n",
        "**The weights may be considered a vector and the magnitude of a vector is called its norm, from linear algebra. As such, penalizing the model based on the size of the weights is also referred to as a weight or parameter norm penalty.**\n",
        "\n",
        "**It is possible to include both L1 and L2 approaches to calculating the size of the weights as the penalty. This is akin to the use of both penalties used in the Elastic Net algorithm for linear and logistic regression.**\n",
        "\n",
        "**The L2 approach is perhaps the most used and is traditionally referred to as “weight decay” in the field of neural networks. It is called “shrinkage” in statistics, a name that encourages you to think of the impact of the penalty on the model weights during the learning process.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ad7F45Nlvgfb",
        "colab_type": "text"
      },
      "source": [
        "##Control Impact of the Penalty\n",
        "**The calculated size of the weights is added to the loss objective function when training the network.**\n",
        "\n",
        "**Rather than adding each weight to the penalty directly, they can be weighted using a new hyperparameter called alpha (a) or sometimes lambda. This controls the amount of attention that the learning process should pay to the penalty. Or put another way, the amount to penalize the model based on the size of the weights.**\n",
        "\n",
        "**The alpha hyperparameter has a value between 0.0 (no penalty) and 1.0 (full penalty). This hyperparameter controls the amount of bias in the model from 0.0, or low bias (high variance), to 1.0, or high bias (low variance).**\n",
        "\n",
        "**If the penalty is too strong, the model will underestimate the weights and underfit the problem. If the penalty is too weak, the model will be allowed to overfit the training data.**\n",
        "\n",
        "**The vector norm of the weights is often calculated per-layer, rather than across the entire network. This allows more flexibility in the choice of the type of regularization used (e.g. L1 for inputs, L2 elsewhere) and flexibility in the alpha value, although it is common to use the same alpha value on each layer by default.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SHefaOtMkv5h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}