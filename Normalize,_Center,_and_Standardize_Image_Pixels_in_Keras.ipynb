{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Normalize, Center, and Standardize Image Pixels in Keras.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/singhbhupender1/ML-notebooks/blob/master/Normalize%2C_Center%2C_and_Standardize_Image_Pixels_in_Keras.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nBDZZaDmYK4L",
        "colab_type": "text"
      },
      "source": [
        "##MNIST Handwritten Image Classification Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ozOurvC4YSV0",
        "colab_type": "text"
      },
      "source": [
        "**The MNIST problem, is an image classification problem comprised of 70,000 images of handwritten digits.**\n",
        "\n",
        "**The goal of the problem is to classify a given image of a handwritten digit as an integer from 0 to 9. As such, it is a multiclass image classification problem.**\n",
        "\n",
        "**This dataset is provided as part of the Keras library and can be automatically downloaded (if needed) and loaded into memory by a call to the keras.datasets.mnist.load_data() function.**\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XtzFbWQGYk8R",
        "colab_type": "text"
      },
      "source": [
        "**The function returns two tuples: one for the training inputs and outputs and one for the test inputs and outputs. For example:**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4nOTeMAEWf--",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        },
        "outputId": "f33a6d68-6fea-4706-9c9b-e64df18f6c12"
      },
      "source": [
        "#load and summerize the mnist dataset\n",
        "from keras.datasets import mnist\n",
        "#load dataset\n",
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
        "#summeriaze dataset shape\n",
        "print('Train', train_images.shape, train_labels.shape)\n",
        "print('Test', test_images.shape, test_labels.shape)\n",
        "#summerize pixel values\n",
        "print('Train', train_images.min(), train_images.max(), train_images.mean(), train_images.std())\n",
        "print('Test', test_images.min(), test_images.max(), test_images.mean(), test_images.std())"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train (60000, 28, 28) (60000,)\n",
            "Test (10000, 28, 28) (10000,)\n",
            "Train 0 255 33.318421449829934 78.56748998339798\n",
            "Test 0 255 33.791224489795916 79.17246322228644\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gfnYyxv4aFhv",
        "colab_type": "text"
      },
      "source": [
        "**We can see that all images are 28 by 28 pixels with a single channel for black-and-white images. There are 60,000 images for the training dataset and 10,000 for the test dataset.**\n",
        "\n",
        "**We can also see that pixel values are integer values between 0 and 255 and that the mean and standard deviation of the pixel values are similar between the two datasets.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dGCFZ4ogaMzX",
        "colab_type": "text"
      },
      "source": [
        "##ImageDataGenerator Class for Pixel Scaling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hI7MCRgAaUbc",
        "colab_type": "text"
      },
      "source": [
        "**The ImageDataGenerator class in Keras provides a suite of techniques for scaling pixel values in your image dataset prior to modeling.**\n",
        "\n",
        "**The class will wrap your image dataset, then when requested, it will return images in batches to the algorithm during training, validation, or evaluation and apply the scaling operations just-in-time. This provides an efficient and convenient approach to scaling image data when modeling with neural networks.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ja_w7eY0aZ21",
        "colab_type": "text"
      },
      "source": [
        "**The usage of the ImageDataGenerator class is as follows.**\n",
        "\n",
        "1. **Load your dataset.**\n",
        "2. **Configure the ImageDataGenerator (e.g. construct an instance).**\n",
        "3. **Calculate image statistics (e.g. call the fit() function).**\n",
        "4. **Use the generator to fit the model (e.g. pass the instance to the fit_generator() function).**\n",
        "5. **Use the generator to evaluate the model (e.g. pass the instance to the evaluate_generator() function).**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LnVQ78BdbKF2",
        "colab_type": "text"
      },
      "source": [
        "**The three main types of pixel scaling techniques supported by the ImageDataGenerator class are as follows:**\n",
        "\n",
        "**Pixel Normalization: scale pixel values to the range 0-1.**\n",
        "\n",
        "**Pixel Centering: scale pixel values to have a zero mean.**\n",
        "\n",
        "**Pixel Standardization: scale pixel values to have a zero mean and unit variance.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4F_wpV38bdfW",
        "colab_type": "text"
      },
      "source": [
        "**The pixel standardization is supported at two levels: either per-image (called sample-wise) or per-dataset (called feature-wise). Specifically, the mean and/or mean and standard deviation statistics required to standardize pixel values can be calculated from the pixel values in each image only (sample-wise) or across the entire training dataset (feature-wise)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EexLbklHbk-Z",
        "colab_type": "text"
      },
      "source": [
        "**The choice of pixel scaling is selected by specifying arguments to the ImageDataGenerator when an instance is constructed; for example**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mWQkTok-bt47",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "```\n",
        "# create and configure the data generator\n",
        "datagen = ImageDataGenerator(...)\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iPWHD9YNbzm_",
        "colab_type": "text"
      },
      "source": [
        "**Next, if the chosen scaling method requires that statistics be calculated across the training dataset, then these statistics can be calculated and stored by calling the fit() function.**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "50EE90FOb5yn",
        "colab_type": "text"
      },
      "source": [
        "**When evaluating and selecting a model, it is common to calculate these statistics on the training dataset and then apply them to the validation and test datasets.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pdWTQV7BcBCx",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "```\n",
        "# calculate scaling statistics on the training dataset\n",
        "datagen.fit(trainX)\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3t5tqAR5cF4C",
        "colab_type": "text"
      },
      "source": [
        "**Once prepared, the data generator can be used to fit a neural network model by calling the flow() function to retrieve an iterator that returns batches of samples and passing it to the fit_generator() function.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VzEUr5CqchlB",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "```\n",
        "# get batch iterator\n",
        "train_iterator = datagen.flow(trainX, trainy)\n",
        "# fit model\n",
        "model.fit_generator(train_iterator, ...)\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q1VPuzI-cmkW",
        "colab_type": "text"
      },
      "source": [
        "**If a validation dataset is required, a separate batch iterator can be created from the same data generator that will perform the same pixel scaling operations and use any required statistics calculated on the training dataset.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4e_BVPlmc39q",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "```\n",
        "# get batch iterator for training\n",
        "train_iterator = datagen.flow(trainX, trainy)\n",
        "# get batch iterator for validation\n",
        "val_iterator = datagen.flow(valX, valy)\n",
        "# fit model\n",
        "model.fit_generator(train_iterator, validation_data=val_iterator, ...)\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BMzSMEOfdIvK",
        "colab_type": "text"
      },
      "source": [
        "**Once fit, the model can be evaluated by creating a batch iterator for the test dataset and calling the evaluate_generator() function on the model.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kY5Fslu6dMLV",
        "colab_type": "text"
      },
      "source": [
        "##How to Normalize Images With ImageDataGenerator"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kELQGtWUdaVb",
        "colab_type": "text"
      },
      "source": [
        "**The ImageDataGenerator class can be used to rescale pixel values from the range of 0-255 to the range 0-1 preferred for neural network models.**\n",
        "\n",
        "**Scaling data to the range of 0-1 is traditionally referred to as normalization.**\n",
        "\n",
        "**This can be achieved by setting the rescale argument to a ratio by which each pixel can be multiplied to achieve the desired range.**\n",
        "\n",
        "**In this case, the ratio is 1/255 or about 0.0039. For exampLE:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z7oCnuC4d0hX",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "```\n",
        "2\n",
        "# create generator (1.0/255.0 = 0.003921568627451)\n",
        "datagen = ImageDataGenerator(rescale=1.0/255.0)\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7I_6so0Wd98X",
        "colab_type": "text"
      },
      "source": [
        "**Next, iterators can be created using the generator for both the train and test datasets. We will use a batch size of 64. This means that each of the train and test datasets of images are divided into groups of 64 images that will then be scaled when returned from the iterator.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AYG26WqaeEQz",
        "colab_type": "text"
      },
      "source": [
        "**We can see how many batches there will be in one epoch, e.g. one pass through the training dataset, by printing the length of each iterator.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lHOIWNi7eLEY",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "```\n",
        "# prepare an iterators to scale images\n",
        "train_iterator = datagen.flow(trainX, trainY, batch_size=64)\n",
        "test_iterator = datagen.flow(testX, testY, batch_size=64)\n",
        "print('Batches train=%d, test=%d' % (len(train_iterator), len(test_iterator)))\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_2_c2K9wgP3B",
        "colab_type": "text"
      },
      "source": [
        "**We can then confirm that the pixel normalization has been performed as expected by retrieving the first batch of scaled images and inspecting the min and max pixel values.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "04GS0Pt3gVZx",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "```\n",
        "# confirm the scaling works\n",
        "batchX, batchy = train_iterator.next()\n",
        "print('Batch shape=%s, min=%.3f, max=%.3f' % (batchX.shape, batchX.min(), batchX.max()))\n",
        "\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xm7BJYvLggbr",
        "colab_type": "text"
      },
      "source": [
        "**Next, we can use the data generator to fit and evaluate a model. We will define a simple convolutional neural network model and fit it on the train_iterator for five epochs with 60,000 samples divided by 64 samples per batch, or about 938 batches per epoch.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SUkHN6hNgl2g",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "```\n",
        "# fit model with generator\n",
        "model.fit_generator(train_iterator, steps_per_epoch=len(train_iterator), epochs=5)\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d7MWP7-Zgq4F",
        "colab_type": "text"
      },
      "source": [
        "**Once fit, we will evaluate the model on the test dataset, with about 10,000 images divided by 64 samples per batch, or about 157 steps in a single epoch.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oKh2ozp3g52Y",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "```\n",
        "_, acc = model.evaluate_generator(test_iterator, steps=len(test_iterator), verbose=0)\n",
        "print('Test Accuracy: %.3f' % (acc * 100))```\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mpeFb3S-ZZg7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "outputId": "07e2a2bd-a169-4482-f140-f156073204e2"
      },
      "source": [
        "#example of using ImageDataGenerator to normalize images\n",
        "from keras.datasets import mnist\n",
        "from keras.utils import to_categorical\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D\n",
        "from keras.layers import MaxPooling2D\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Flatten\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "#load dataset\n",
        "(trainX, trainY), (testX, testY) = mnist.load_data()\n",
        "#reshape datast to a single channel\n",
        "width, height, channels = trainX.shape[1], trainX.shape[2], 1\n",
        "trainX = trainX.reshape(trainX.shape[0], width, height, channels)\n",
        "testX = testX.reshape(testX.shape[0], width, height, channels)\n",
        "#one hot encoding of labels\n",
        "testY = to_categorical(testY)\n",
        "trainY = to_categorical(trainY)\n",
        "#confirm scale of pixels\n",
        "print(\"Train min=%.3f, max=%.3f\" % (trainX.min(), trainX.max()))\n",
        "print(\"test moin=%.3f, max=%.3f\" % (testX.min(), testX.max()))\n",
        "#cretae generator (1.0/255/0 = 0.003921568627451)\n",
        "datagen = ImageDataGenerator(rescale=1.0/255.0)\n",
        "#Prepare on iteratore to scale images\n",
        "train_iterators = datagen.flow(trainX, trainY, batch_size=64)\n",
        "test_iterators = datagen.flow(testX, testY, batch_size=64)\n",
        "print('Batches train=%d, test=%d' % (len(train_iterators), len(test_iterators)))\n",
        "#confirm the scaling works\n",
        "batchX, batchy = train_iterators.next()\n",
        "print('Batches shape=%s, min=%.3f, max=%.3f' % (batchX.shape, batchX.min(), batchX.max()))\n",
        "#define model\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(width, height, channels)))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "#compile model\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "#fit model with generator\n",
        "model.fit_generator(train_iterators, steps_per_epoch= len(train_iterators), epochs =5)\n",
        "#evaluate the model\n",
        "_, acc = model.evaluate_generator(test_iterators, steps=len(test_iterators), verbose=0)\n",
        "print('test accuaracy: %.3f' % (acc * 100))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train min=0.000, max=255.000\n",
            "test moin=0.000, max=255.000\n",
            "Batches train=938, test=157\n",
            "Batches shape=(64, 28, 28, 1), min=0.000, max=1.000\n",
            "Epoch 1/5\n",
            "938/938 [==============================] - 44s 47ms/step - loss: 0.1726 - acc: 0.9481\n",
            "Epoch 2/5\n",
            "938/938 [==============================] - 44s 47ms/step - loss: 0.0521 - acc: 0.9840\n",
            "Epoch 3/5\n",
            "938/938 [==============================] - 44s 47ms/step - loss: 0.0358 - acc: 0.9886\n",
            "Epoch 4/5\n",
            "938/938 [==============================] - 44s 46ms/step - loss: 0.0278 - acc: 0.9914\n",
            "Epoch 5/5\n",
            "938/938 [==============================] - 44s 47ms/step - loss: 0.0219 - acc: 0.9929\n",
            "test accuaracy: 99.030\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ff6rxcmcn-uX",
        "colab_type": "text"
      },
      "source": [
        "**Running the example first reports the min and max pixel values on the train and test sets. This confirms that indeed the raw data has pixel values in the range 0-255.**\n",
        "\n",
        "**Next, the data generator is created and the iterators are prepared. We can see that we have 938 batches per epoch with the training dataset and 157 batches per epoch with the test dataset.**\n",
        "\n",
        "**We retrieve the first batch from the dataset and confirm that it contains 64 images with the height and width (rows and columns) of 28 pixels and 1 channel, and that the new minimum and maximum pixel values are 0 and 1 respectively. This confirms that the normalization has had the desired effect.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rIiWXWnsuOI0",
        "colab_type": "text"
      },
      "source": [
        "##How to Center Images With ImageDataGenerator"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "szTE-AAN4f_Z",
        "colab_type": "text"
      },
      "source": [
        "**Another popular pixel scaling method is to calculate the mean pixel value across the entire training dataset, then subtract it from each image.**\n",
        "\n",
        "**This is called centering and has the effect of centering the distribution of pixel values on zero: that is, the mean pixel value for centered images will be zero.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KjYM3eZP4tEG",
        "colab_type": "text"
      },
      "source": [
        "**The ImageDataGenerator class refers to centering that uses the mean calculated on the training dataset as feature-wise centering. It requires that the statistic is calculated on the training dataset prior to scaling.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UZ3POqWo43Ka",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "```\n",
        "# create generator that centers pixel values\n",
        "datagen = ImageDataGenerator(featurewise_center=True)\n",
        "# calculate the mean on the training dataset\n",
        "datagen.fit(trainX)\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SXqyd6tc5QFw",
        "colab_type": "text"
      },
      "source": [
        "**It is different to calculating of the mean pixel value for each image, which Keras refers to as sample-wise centering and does not require any statistics to be calculated on the training dataset.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wjTz-N7X5UMz",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "```\n",
        "# create generator that centers pixel values\n",
        "datagen = ImageDataGenerator(samplewise_center=True)\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m0KoQdn15gp4",
        "colab_type": "text"
      },
      "source": [
        "**We will demonstrate feature-wise centering in this section. Once the statistic is calculated on the training dataset, we can confirm the value by accessing and printing it; for example:**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8pZjHXrN5rq_",
        "colab_type": "text"
      },
      "source": [
        "**We can also confirm that the scaling procedure has had the desired effect by calculating the mean of a batch of images returned from the batch iterator. We would expect the mean to be a small value close to zero, but not zero because of the small number of images in the batch.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3obImalC8LEC",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "```\n",
        "# get a batch\n",
        "batchX, batchy = iterator.next()\n",
        "# mean pixel value in the batch\n",
        "print(batchX.shape, batchX.mean())\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8g5HbjjW8QkA",
        "colab_type": "text"
      },
      "source": [
        "**A better check would be to set the batch size to the size of the training dataset (e.g. 60,000 samples), retrieve one batch, then calculate the mean. It should be a very small value close to zero.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s06ACJ-B8VHy",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "```\n",
        "# try to flow the entire training dataset\n",
        "iterator = datagen.flow(trainX, trainy, batch_size=len(trainX), shuffle=False)\n",
        "# get a batch\n",
        "batchX, batchy = iterator.next()\n",
        "# mean pixel value in the batch\n",
        "print(batchX.shape, batchX.mean())\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OkInHz225q04",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        },
        "outputId": "3ab1452f-b4a5-4bb9-8428-9876ed67660b"
      },
      "source": [
        "#example of centering a image dataset\n",
        "from keras.datasets import mnist\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "#load dataset\n",
        "(trainX, trainY), (testX, testY) = mnist.load_data()\n",
        "#reshape dataset to have a single channel\n",
        "width, height, channels = trainX.shape[1], trainX.shape[2], 1\n",
        "trainX = trainX.reshape(trainX.shape[0], width, height, channels)\n",
        "testX = testX.reshape(testX.shape[0], width, height, channels)\n",
        "#report per-image mean\n",
        "print('Means train=%.3f, test=%.3f' % (trainX.mean(), testX.mean()))\n",
        "#create generator that centers pxiel values\n",
        "datagen = ImageDataGenerator(featurewise_center=True)\n",
        "#calculate the mean of the training datset\n",
        "datagen.fit(trainX)\n",
        "print('Data generator Mean: %.3f' % datagen.mean)\n",
        "#Demonstrate effect on a single batch of samples\n",
        "iterator = datagen.flow(trainX, trainY, batch_size=64)\n",
        "#get a batch\n",
        "batchX, batchy = iterator.next()\n",
        "#mean pixel value in the batch\n",
        "print(batchX.shape, batchX.mean())\n",
        "#demonstrate effect on entire training dataset\n",
        "iterator = datagen.flow(trainX, trainY, batch_size=len(trainX),shuffle=False)\n",
        "#get a batch\n",
        "batchX, batchY = iterator.next()\n",
        "#mean pixel value in the batch\n",
        "print(batchX.shape, batchX.mean())\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Means train=33.318, test=33.791\n",
            "Data generator Mean: 33.318\n",
            "(64, 28, 28, 1) 2.0771394\n",
            "(60000, 28, 28, 1) -1.9512918e-05\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YhbWDndwCmWb",
        "colab_type": "text"
      },
      "source": [
        "**The MNIST dataset only has a single channel because the images are black and white (grayscale), but if the images were color, the mean pixel values would be calculated across all channels in all images in the training dataset, i.e. there would not be a separate mean value for each channel.**\n",
        "\n",
        "**The ImageDataGenerator is fit on the training dataset and we can confirm that the mean pixel value matches our own manual calculation.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xTizvZMZCu6_",
        "colab_type": "text"
      },
      "source": [
        "**A single batch of centered images is retrieved and we can confirm that the mean pixel value is a small-ish value close to zero. The test is repeated using the entire training dataset as a the batch size, and in this case, the mean pixel value for the scaled dataset is a number very close to zero, confirming that centering is having the desired effect.**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lmyEI3s2m0CX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 759
        },
        "outputId": "e2277846-3572-48fe-a7b5-964751d0cf54"
      },
      "source": [
        "# example of using ImageDataGenerator to center images\n",
        "from keras.datasets import mnist\n",
        "from keras.utils import to_categorical\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D\n",
        "from keras.layers import MaxPooling2D\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Flatten\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "# load dataset\n",
        "(trainX, trainY), (testX, testY) = mnist.load_data()\n",
        "# reshape dataset to have a single channel\n",
        "width, height, channels = trainX.shape[1], trainX.shape[2], 1\n",
        "trainX = trainX.reshape((trainX.shape[0], width, height, channels))\n",
        "testX = testX.reshape((testX.shape[0], width, height, channels))\n",
        "# one hot encode target values\n",
        "trainY = to_categorical(trainY)\n",
        "testY = to_categorical(testY)\n",
        "# create generator to center images\n",
        "datagen = ImageDataGenerator(featurewise_center=True)\n",
        "# calculate mean on training dataset\n",
        "datagen.fit(trainX)\n",
        "# prepare an iterators to scale images\n",
        "train_iterator = datagen.flow(trainX, trainY, batch_size=64)\n",
        "test_iterator = datagen.flow(testX, testY, batch_size=64)\n",
        "print('Batches train=%d, test=%d' % (len(train_iterator), len(test_iterator)))\n",
        "# define model\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(width, height, channels)))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "# compile model\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "# fit model with generator\n",
        "model.fit_generator(train_iterator, steps_per_epoch=len(train_iterator), epochs=5)\n",
        "# evaluate model\n",
        "_, acc = model.evaluate_generator(test_iterator, steps=len(test_iterator), verbose=0)\n",
        "print('Test Accuracy: %.3f' % (acc * 100))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Batches train=938, test=157\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "Epoch 1/5\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "938/938 [==============================] - 44s 47ms/step - loss: 1.0774 - acc: 0.9008\n",
            "Epoch 2/5\n",
            "938/938 [==============================] - 43s 46ms/step - loss: 0.0610 - acc: 0.9821\n",
            "Epoch 3/5\n",
            "938/938 [==============================] - 43s 46ms/step - loss: 0.0452 - acc: 0.9863\n",
            "Epoch 4/5\n",
            "938/938 [==============================] - 43s 46ms/step - loss: 0.0345 - acc: 0.9896\n",
            "Epoch 5/5\n",
            "938/938 [==============================] - 43s 46ms/step - loss: 0.0402 - acc: 0.9880\n",
            "Test Accuracy: 98.820\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vTeaVG8UIn9U",
        "colab_type": "text"
      },
      "source": [
        "**Running the example prepares the ImageDataGenerator, centering images using statistics calculated on the training dataset.**\n",
        "\n",
        "**We can see that performance starts off poor but does improve. The centered pixel values will have a range of about -227 to 227, and neural networks often train more efficiently with small inputs. Normalizing followed by centering would be a better approach in practice.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dC6a3lGXI0e_",
        "colab_type": "text"
      },
      "source": [
        "##How to Standardize Image With ImageDataGenerator"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wYH1eFKaI-bb",
        "colab_type": "text"
      },
      "source": [
        "**Standardization is a data scaling technique that assumes that the distribution of the data is Gaussian and shifts the distribution of the data to have a mean of zero and a standard deviation of one.**\n",
        "\n",
        "**Data with this distribution is referred to as a standard Gaussian. It can be beneficial when training neural networks as the dataset sums to zero and the inputs are small values in the rough range of about -3.0 to 3.0 (e.g. 99.7 of the values will fall within three standard deviations of the mean).**\n",
        "\n",
        "**Standardization of images is achieved by subtracting the mean pixel value and dividing the result by the standard deviation of the pixel values.**\n",
        "\n",
        "**The mean and standard deviation statistics can be calculated on the training dataset, and as discussed in the previous section, Keras refers to this as feature-wise.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ri6gVIzNJt9e",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "```\n",
        "# feature-wise generator\n",
        "datagen = ImageDataGenerator(featurewise_center=True, featurewise_std_normalization=True)\n",
        "# calculate mean and standard deviation on the training dataset\n",
        "datagen.fit(trainX)\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BKmx7kkLLHkT",
        "colab_type": "text"
      },
      "source": [
        "**The statistics can also be calculated then used to standardize each image separately, and Keras refers to this as sample-wise standardization.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CvpeR8rwLMbC",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "```\n",
        "# sample-wise standardization\n",
        "datagen = ImageDataGenerator(samplewise_center=True, samplewise_std_normalization=True)\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7mEjIRARC59A",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        },
        "outputId": "160ddf26-5534-4b6e-c6b4-73d4a7a64e7e"
      },
      "source": [
        "from keras.datasets import mnist\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "# load dataset\n",
        "(trainX, trainy), (testX, testy) = mnist.load_data()\n",
        "# reshape dataset to have a single channel\n",
        "width, height, channels = trainX.shape[1], trainX.shape[2], 1\n",
        "trainX = trainX.reshape((trainX.shape[0], width, height, channels))\n",
        "testX = testX.reshape((testX.shape[0], width, height, channels))\n",
        "# report pixel means and standard deviations\n",
        "print('Statistics train=%.3f (%.3f), test=%.3f (%.3f)' % (trainX.mean(), trainX.std(), testX.mean(), testX.std()))\n",
        "# create generator that centers pixel values\n",
        "datagen = ImageDataGenerator(featurewise_center=True, featurewise_std_normalization=True)\n",
        "# calculate the mean on the training dataset\n",
        "datagen.fit(trainX)\n",
        "print('Data Generator mean=%.3f, std=%.3f' % (datagen.mean, datagen.std))\n",
        "# demonstrate effect on a single batch of samples\n",
        "iterator = datagen.flow(trainX, trainy, batch_size=64)\n",
        "# get a batch\n",
        "batchX, batchy = iterator.next()\n",
        "# pixel stats in the batch\n",
        "print(batchX.shape, batchX.mean(), batchX.std())\n",
        "# demonstrate effect on entire training dataset\n",
        "iterator = datagen.flow(trainX, trainy, batch_size=len(trainX), shuffle=False)\n",
        "# get a batch\n",
        "batchX, batchy = iterator.next()\n",
        "# pixel stats in the batch\n",
        "print(batchX.shape, batchX.mean(), batchX.std())"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Statistics train=33.318 (78.567), test=33.791 (79.172)\n",
            "Data Generator mean=33.318, std=78.567\n",
            "(64, 28, 28, 1) 0.00055489736 0.99989814\n",
            "(60000, 28, 28, 1) -3.4560264e-07 0.9999998\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lQ7ArsbULhzU",
        "colab_type": "text"
      },
      "source": [
        "**Running the example first reports the mean and standard deviation of pixel values in the train and test datasets.**\n",
        "\n",
        "**The data generator is then configured for feature-wise standardization and the statistics are calculated on the training dataset, matching what we would expect when the statistics are calculated manually.**\n",
        "\n",
        "**A single batch of 64 standardized images is then retrieved and we can confirm that the mean and standard deviation of this small sample is close to the expected standard Gaussian.**\n",
        "\n",
        "**The test is then repeated on the entire training dataset and we can confirm that the mean is indeed a very small value close to 0.0 and the standard deviation is a value very close to 1.0.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M2ODof2sLb_M",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        },
        "outputId": "6d1d7824-be73-4726-ecd3-1f150525a698"
      },
      "source": [
        "# example of using ImageDataGenerator to standardize images\n",
        "from keras.datasets import mnist\n",
        "from keras.utils import to_categorical\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D\n",
        "from keras.layers import MaxPooling2D\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Flatten\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "# load dataset\n",
        "(trainX, trainY), (testX, testY) = mnist.load_data()\n",
        "# reshape dataset to have a single channel\n",
        "width, height, channels = trainX.shape[1], trainX.shape[2], 1\n",
        "trainX = trainX.reshape((trainX.shape[0], width, height, channels))\n",
        "testX = testX.reshape((testX.shape[0], width, height, channels))\n",
        "# one hot encode target values\n",
        "trainY = to_categorical(trainY)\n",
        "testY = to_categorical(testY)\n",
        "# create generator to standardize images\n",
        "datagen = ImageDataGenerator(featurewise_center=True, featurewise_std_normalization=True)\n",
        "# calculate mean on training dataset\n",
        "datagen.fit(trainX)\n",
        "# prepare an iterators to scale images\n",
        "train_iterator = datagen.flow(trainX, trainY, batch_size=64)\n",
        "test_iterator = datagen.flow(testX, testY, batch_size=64)\n",
        "print('Batches train=%d, test=%d' % (len(train_iterator), len(test_iterator)))\n",
        "# define model\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(width, height, channels)))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "# compile model\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "# fit model with generator\n",
        "model.fit_generator(train_iterator, steps_per_epoch=len(train_iterator), epochs=5)\n",
        "# evaluate model\n",
        "_, acc = model.evaluate_generator(test_iterator, steps=len(test_iterator), verbose=0)\n",
        "print('Test Accuracy: %.3f' % (acc * 100))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Batches train=938, test=157\n",
            "Epoch 1/5\n",
            "938/938 [==============================] - 45s 48ms/step - loss: 0.1397 - acc: 0.9580\n",
            "Epoch 2/5\n",
            "938/938 [==============================] - 45s 48ms/step - loss: 0.0441 - acc: 0.9865\n",
            "Epoch 3/5\n",
            "938/938 [==============================] - 44s 47ms/step - loss: 0.0306 - acc: 0.9905\n",
            "Epoch 4/5\n",
            "938/938 [==============================] - 45s 48ms/step - loss: 0.0236 - acc: 0.9923\n",
            "Epoch 5/5\n",
            "938/938 [==============================] - 45s 48ms/step - loss: 0.0178 - acc: 0.9942\n",
            "Test Accuracy: 98.950\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kSFmwCOUOeD3",
        "colab_type": "text"
      },
      "source": [
        "**Running the example configures the ImageDataGenerator class to standardize images, calculates the required statistics on the training set only, then prepares the train and test iterators for fitting and evaluating the model respectively.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lB8FHQS6LxAs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}