{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "How to Manually Scale Image Pixel Data.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/singhbhupender1/ML-notebooks/blob/master/How_to_Manually_Scale_Image_Pixel_Data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WeodBgL3lKF1",
        "colab_type": "text"
      },
      "source": [
        "##Manually Scale Image Pixel Data for Deep Learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UxKdaYDJluqQ",
        "colab_type": "text"
      },
      "source": [
        "**Black and white images are single matrix of pixels, whereas color images have a separate array of pixel values for each color channel, such as red, green, and blue.**\n",
        "\n",
        "**Pixel values are often unsigned integers in the range between 0 and 255. Although these pixel values can be presented directly to neural network models in their raw format, this can result in challenges during modeling, such as in the slower than expected training of the model.**\n",
        "\n",
        "**Instead, there can be great benefit in preparing the image pixel values prior to modeling, such as simply scaling pixel values to the range 0-1 to centering and even standardizing the values.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WemlDmj-k-mm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "32adf1dc-d719-4266-81f6-c28c483cefbe"
      },
      "source": [
        "#load and show an image with Pillow\n",
        "from PIL import Image\n",
        "from urllib.request import urlopen\n",
        "#load the image\n",
        "url  = 'https://3qeqpr26caki16dnhd19sv6by6v-wpengine.netdna-ssl.com/wp-content/uploads/2019/01/The-Sydney-Harbor-Bridge-Photograph-Loaded-From-File.png'\n",
        "image = Image.open(urlopen(url))\n",
        "#Summerize some details about the Image\n",
        "print(image.format)\n",
        "print(image.mode)\n",
        "print(image.size)\n",
        "#show the image\n",
        "image.show()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "PNG\n",
            "RGBA\n",
            "(1280, 856)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VNbg2qponf6a",
        "colab_type": "text"
      },
      "source": [
        "##Normalize Pixel Values"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iCYTRguqnvZh",
        "colab_type": "text"
      },
      "source": [
        "**For most image data, the pixel values are integers with values between 0 and 255.**\n",
        "\n",
        "**Neural networks process inputs using small weight values, and inputs with large integer values can disrupt or slow down the learning process. As such it is good practice to normalize the pixel values so that each pixel value has a value between 0 and 1.**\n",
        "\n",
        "**It is valid for images to have pixel values in the range 0-1 and images can be viewed normally.**\n",
        "\n",
        "**This can be achieved by dividing all pixels values by the largest pixel value; that is 255. This is performed across all channels, regardless of the actual range of pixel values that are present in the image.**\n",
        "\n",
        "**The example below loads the image and converts it into a NumPy array. The data type of the array is reported and the minimum and maximum pixels values across all three channels are then printed. Next, the array is converted to the float data type before the pixel values are normalized and the new range of pixel values is reported.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OQaCZxFunKbF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "3b6a4f75-0afb-46ec-bd83-b4370917b618"
      },
      "source": [
        "#example of pixel normalization\n",
        "from numpy import asarray\n",
        "from PIL import Image\n",
        "from urllib.request import urlopen\n",
        "#load image\n",
        "url = 'https://3qeqpr26caki16dnhd19sv6by6v-wpengine.netdna-ssl.com/wp-content/uploads/2019/01/The-Sydney-Harbor-Bridge-Photograph-Loaded-From-File.png'\n",
        "img = Image.open(urlopen(url))\n",
        "pixels = asarray(img)\n",
        "#confirm pixel range is 0-255\n",
        "print('Data type : %s' % pixels.dtype)\n",
        "print('Min: %.3f, Max: %.3f' % (pixels.min(), pixels.max()))\n",
        "#convert from intergers to floats\n",
        "pixels = pixels.astype('float32')\n",
        "#normalize to the range 0-1\n",
        "pixels /= 255.0\n",
        "#confirm the normalization\n",
        "print('Min: %.3f, Max:%.3f' % (pixels.min(), pixels.max()))"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Data type : uint8\n",
            "Min: 0.000, Max: 255.000\n",
            "Min: 0.000, Max:1.000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "690x0d4Q1Uv4",
        "colab_type": "text"
      },
      "source": [
        "**Normalization is a good default data preparation that can be performed if you are in doubt as to the type of data preparation to perform.**\n",
        "\n",
        "**It can be performed per image and does not require the calculation of statistics across the training dataset, as the range of pixel values is a domain standard.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sQbg_P6m1bJC",
        "colab_type": "text"
      },
      "source": [
        "##Center Pixel Values"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F0EuEb_41gxW",
        "colab_type": "text"
      },
      "source": [
        "**A popular data preparation technique for image data is to subtract the mean value from the pixel values.**\n",
        "\n",
        "**This approach is called centering, as the distribution of the pixel values is centered on the value of zero.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XmvADXXB17_5",
        "colab_type": "text"
      },
      "source": [
        "**Centering can be performed before or after normalization. Centering the pixels then normalizing will mean that the pixel values will be centered close to 0.5 and be in the range 0-1. Centering after normalization will mean that the pixels will have positive and negative values, in which case images will not display correctly (e.g. pixels are expected to have value in the range 0-255 or 0-1). Centering after normalization might be preferred, although it might be worth testing both approaches.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PIfAHySX2Udb",
        "colab_type": "text"
      },
      "source": [
        "**Centering requires that a mean pixel value be calculated prior to subtracting it from the pixel values. There are multiple ways that the mean can be calculated; for example:**\n",
        "\n",
        ">**Per image.**\n",
        "\n",
        ">**Per mini-batch of images (under stochastic gradient descent).**\n",
        "\n",
        ">**Per training dataset.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xLBnX6_q2_4E",
        "colab_type": "text"
      },
      "source": [
        "**The mean can be calculated for all pixels in the image, referred to as a global centering, or it can be calculated for each channel in the case of color images, referred to as local centering.**\n",
        "\n",
        "**Global Centering: Calculating and subtracting the mean pixel value across color channels.**\n",
        "\n",
        "**Local Centering: Calculating and subtracting the mean pixel value per color channel.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bQyv3YbV5Zu4",
        "colab_type": "text"
      },
      "source": [
        "**Per-image global centering is common because it is trivial to implement. Also common is per mini-batch global or local centering for the same reason: it is fast and easy to implement.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wcyreLU65uK_",
        "colab_type": "text"
      },
      "source": [
        "**In some cases, per-channel means are pre-calculated across an entire training dataset. In this case, the image means must be stored and used both during training and any inference with the trained models in the future. For example, the per-channel pixel means calculated for the ImageNet training dataset are as follows:**\n",
        "\n",
        "**ImageNet Training Dataset Means: [0.485, 0.456, 0.406]**\n",
        "\n",
        "**For models trained on images centered using these means that may be used for transfer learning on new tasks, it can be beneficial or even required to normalize images for the new task using the same means.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5PGtLSfD5_cv",
        "colab_type": "text"
      },
      "source": [
        "##Global Centering"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0jYhdRsT0ZaB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        },
        "outputId": "fde8cdd9-a72f-40cd-880d-da29dc3b21b0"
      },
      "source": [
        "#example of global centering(subtract mean)\n",
        "from numpy import asarray\n",
        "from PIL import Image\n",
        "from urllib.request import urlopen\n",
        "#load image\n",
        "url = 'https://3qeqpr26caki16dnhd19sv6by6v-wpengine.netdna-ssl.com/wp-content/uploads/2019/01/The-Sydney-Harbor-Bridge-Photograph-Loaded-From-File.png'\n",
        "image = Image.open(urlopen(url))\n",
        "pixels = asarray(image)\n",
        "#convert from intergers to floats\n",
        "pixels = pixels.astype('float32')\n",
        "#calculate gloabal mean\n",
        "mean = pixels.mean()\n",
        "print('Mean:%.3f' % mean)\n",
        "print('Min:%.3f, Max:%.3f' % (pixels.min(), pixels.max()))\n",
        "#global centering of pixels\n",
        "pixels = pixels - mean\n",
        "#confirm it had the desired effect\n",
        "mean = pixels.mean()\n",
        "print('Mean: %.3f' % mean)\n",
        "print('Min:%.3f, Max:%.3f' % (pixels.min(), pixels.max()))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mean:184.501\n",
            "Min:0.000, Max:255.000\n",
            "Mean: -0.000\n",
            "Min:-184.501, Max:70.499\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_BEEFscp8W3d",
        "colab_type": "text"
      },
      "source": [
        "##Local Centering"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s-F8VLta8c6Z",
        "colab_type": "text"
      },
      "source": [
        "**NumPy allows us to specify the dimensions over which a statistic like the mean, min, and max are calculated via the “axis” argument. In this example, we set this to (0,1) for the width and height dimensions, which leaves the third dimension or channels. The result is one mean, min, or max for each of the three channel arrays.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zFYZHhe98is0",
        "colab_type": "text"
      },
      "source": [
        "**when we calculate the mean that we specify the dtype as ‘float64‘; this is required as it will cause all sub-operations of the mean, such as the sum, to be performed with 64-bit precision. Without this, the sum will be performed at lower resolution and the resulting mean will be wrong given the accumulated errors in the loss of precision, in turn meaning the mean of the centered pixel values for each channel will not be zero (or a very small number close to zero)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wftBXGzQ8GvN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "outputId": "ed5c4614-91e9-4ee3-a814-a3697113f0a5"
      },
      "source": [
        "#examplr of per-channel centering(subtract mean)\n",
        "from numpy import asarray\n",
        "from PIL import Image\n",
        "from urllib.request import urlopen\n",
        "#load image\n",
        "url = 'https://3qeqpr26caki16dnhd19sv6by6v-wpengine.netdna-ssl.com/wp-content/uploads/2019/01/The-Sydney-Harbor-Bridge-Photograph-Loaded-From-File.png'\n",
        "image = Image.open(urlopen(url))\n",
        "pixels = asarray(image)\n",
        "#convert from integers to pixels\n",
        "pixels = pixels.astype('float32')\n",
        "#calculate per-channel menas and standard deviations\n",
        "means = pixels.mean(axis=(0,1), dtype='float64')\n",
        "print('Mean: %s' %means)\n",
        "print('Mins:%s, Maxs:%s' % (pixels.min(axis=(0,1)), pixels.max(axis=(0,1))))\n",
        "#per-channel centering of pixels\n",
        "pixels -= means\n",
        "#confirm it has the desired effect\n",
        "means = pixels.mean(axis=(0,1), dtype='float64')\n",
        "print('Means: %s' % means)\n",
        "print('Min:%s, Max:%s' % (pixels.min(axis=(0,1)), pixels.max(axis=(0,1))))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mean: [158.43480487 159.58662109 164.9829202  255.        ]\n",
            "Mins:[  0.   0.   0. 255.], Maxs:[255. 255. 255. 255.]\n",
            "Means: [-3.06365524e-07 -1.24562507e-06  4.88580506e-07  0.00000000e+00]\n",
            "Min:[-158.4348  -159.58662 -164.98293    0.     ], Max:[96.56519  95.413376 90.01708   0.      ]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xdk1YDL4EJSw",
        "colab_type": "text"
      },
      "source": [
        "##Standardize Pixel Values"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Q77VdwTEOP2",
        "colab_type": "text"
      },
      "source": [
        "**The distribution of pixel values often follows a Normal or Gaussian distribution, e.g. bell shape.**\n",
        "\n",
        "**This distribution may be present per image, per mini-batch of images, or across the training dataset and globally or per channel.**\n",
        "\n",
        "**As such, there may be benefit in transforming the distribution of pixel values to be a standard Gaussian: that is both centering the pixel values on zero and normalizing the values by the standard deviation. The result is a standard Gaussian of pixel values with a mean of 0.0 and a standard deviation of 1.0.**\n",
        "\n",
        "**As with centering, the operation can be performed per image, per mini-batch, and across the entire training dataset, and it can be performed globally across channels or locally per channel.**\n",
        "\n",
        "**Standardization may be preferred to normalization and centering alone and it results in both zero-centered values of small input values, roughly in the range -3 to 3, depending on the specifics of the dataset.**\n",
        "\n",
        "**For consistency of the input data, it may make more sense to standardize images per-channel using statistics calculated per mini-batch or across the training dataset, if possible.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8WZzmjGCFJTv",
        "colab_type": "text"
      },
      "source": [
        "##Global Standardization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D6YQ_u5HDkGo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "f89c2fd5-9c3f-45cc-ec6d-614d6b479e83"
      },
      "source": [
        "#example of global pixel standardization\n",
        "from numpy import asarray\n",
        "from PIL import Image\n",
        "from urllib.request import urlopen\n",
        "#load the image\n",
        "url = 'https://3qeqpr26caki16dnhd19sv6by6v-wpengine.netdna-ssl.com/wp-content/uploads/2019/01/The-Sydney-Harbor-Bridge-Photograph-Loaded-From-File.png'\n",
        "image = Image.open(urlopen(url))\n",
        "pixels = asarray(image)\n",
        "#convert from integers to floats\n",
        "pixels = pixels.astype('float32')\n",
        "#calculate global mean and standard deviation\n",
        "mean, std = pixels.mean(), pixels.std()\n",
        "print('Mean: %.3f, Standard deviation:%.3f' % (mean, std))\n",
        "#global standardization of pixels\n",
        "pixels = (pixels - mean)/ std\n",
        "#confirm it had the desird effect\n",
        "mean, std = pixels.mean(), pixels.std()\n",
        "print('Means: %.3f, standard deviation:%.3f' % (mean, std))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mean: 184.501, Standard deviation:73.418\n",
            "Means: -0.000, standard deviation:1.000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7UVxQdtBH5gP",
        "colab_type": "text"
      },
      "source": [
        "##Positive Global Standardization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "27XV97fRH-7g",
        "colab_type": "text"
      },
      "source": [
        "**There may be a desire to maintain the pixel values in the positive domain, perhaps so the images can be visualized or perhaps for the benefit of a chosen activation function in the model.**\n",
        "\n",
        "**A popular way of achieving this is to clip the standardized pixel values to the range [-1, 1] and then rescale the values from [-1,1] to [0,1].**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QpU9IDOeHtv_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "5753a450-5fa5-4be1-a831-5d5a72a04310"
      },
      "source": [
        "#example of global pixels standardizaton shifted to positive domain\n",
        "from numpy import asarray\n",
        "from numpy import clip\n",
        "from PIL import Image\n",
        "from urllib.request import urlopen\n",
        "#load image\n",
        "url = 'https://3qeqpr26caki16dnhd19sv6by6v-wpengine.netdna-ssl.com/wp-content/uploads/2019/01/The-Sydney-Harbor-Bridge-Photograph-Loaded-From-File.png'\n",
        "pixels = Image.open(urlopen(url))\n",
        "pixels = asarray(pixels)\n",
        "#convert from intefers to float\n",
        "pixels = pixels.astype('float32')\n",
        "#calcualte global mean and standard deviation\n",
        "mean, std = pixels.mean(), pixels.std()\n",
        "print('Mean:%.3f, standard deviation:%.3f' % (mean, std))\n",
        "#global standardization of pixels\n",
        "pixels = (pixels - mean) / std\n",
        "#clip pixel values ot [-1, 1]\n",
        "pixels = clip(pixels, -1.0, 1.0)\n",
        "#shift from [-1, 1] to [0,1] with 0.5 mean\n",
        "pixels = (pixels + 1.0) / 2.0\n",
        "#confirm it has the desired effect\n",
        "mean, std = pixels.mean(), pixels.std()\n",
        "print('Mean:%.3f, standard deviation:%.3f' % (mean, std))\n",
        "print('Min:%.3f, Max:%.3f' % (pixels.min(), pixels.max())) "
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mean:184.501, standard deviation:73.418\n",
            "Mean:0.563, standard deviation:0.396\n",
            "Min:0.000, Max:0.980\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Xq6ZEr7MKMd",
        "colab_type": "text"
      },
      "source": [
        "##Local Standardization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-SSyqha1LdND",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "outputId": "c4e9ddc5-cbce-4ada-b65b-6d04a4b3d7b4"
      },
      "source": [
        "#example of per-channe; pixel standardization\n",
        "from numpy import asarray\n",
        "from PIL import Image\n",
        "from urllib.request import urlopen\n",
        "#load image\n",
        "url = 'https://3qeqpr26caki16dnhd19sv6by6v-wpengine.netdna-ssl.com/wp-content/uploads/2019/01/The-Sydney-Harbor-Bridge-Photograph-Loaded-From-File.png'\n",
        "image = Image.open(urlopen(url))\n",
        "pixels = asarray(image)\n",
        "#convert from integers to floats\n",
        "pixels = pixels.astype('float32')\n",
        "#calculate per-channel means and standard deviations\n",
        "means = pixels.mean(axis=(0,1), dtype='float64')\n",
        "stds = pixels.std(axis=(0,1), dtype='float64')\n",
        "print('Means:%s, Stds:%s' %(means, stds))\n",
        "#per-channel standardization of pixels\n",
        "pixels = (pixels - means) / stds\n",
        "#confimr it had the desired effect\n",
        "means = pixels.mean(axis=(0,1), dtype='float64')\n",
        "stds = pixels.std(axis=(0,1), dtype='float64')\n",
        "print('Means:%s, Stds:%s' % (means, stds))\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Means:[158.43480487 159.58662109 164.9829202  255.        ], Stds:[70.63586854 70.73750037 70.1171148   0.        ]\n",
            "Means:[-3.98300453e-13 -1.93157989e-13  3.25967320e-13             nan], Stds:[ 1.  1.  1. nan]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:15: RuntimeWarning: invalid value encountered in true_divide\n",
            "  from ipykernel import kernelapp as app\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gYszBn7rOBvZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}